{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f150ac1f",
   "metadata": {},
   "source": [
    "# Database AI Agents: Text-to-SQL for HR Recruitment\n",
    "\n",
    "This notebook demonstrates **Database AI Agent development** for AI-powered data analysis by building an agent that:\n",
    "\n",
    "1. **Converts natural language to SQL** - Translates HR questions into database queries\n",
    "2. **Enforces safety guardrails** - Read-only operations, table whitelisting, row limits\n",
    "3. **Applies time constraints** - Automatic filtering for recent data\n",
    "4. **Generates professional summaries** - Clear explanations for HR teams\n",
    "\n",
    "## Key Concepts Demonstrated\n",
    "\n",
    "- **Natural Language to SQL**: Using LLMs to convert questions to queries\n",
    "- **Safety Guardrails**: Preventing dangerous database operations\n",
    "- **Schema-Aware Processing**: Understanding database structure and relationships\n",
    "- **Error Handling & Retry Logic**: Graceful failure recovery\n",
    "- **Professional Output Generation**: Business-ready summaries\n",
    "\n",
    "## Scenario\n",
    "An HR analytics agent that helps recruitment teams get insights from their hiring database without writing SQL. The agent answers questions about candidates, interviews, offers, and hiring pipelines.\n",
    "\n",
    "**Note**: This demo uses **SQLite** for simplicity, but the same patterns work with PostgreSQL, MySQL, or other databases via SQLAlchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9261e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Environment Setup:\n",
      "   ‚úÖ OpenAI API Key: ‚úì Configured\n",
      "   üîß Database: Using SQLite for demo\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client with Vocareum endpoint\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openai.vocareum.com/v1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "print(\"üîß Environment Setup:\")\n",
    "print(f\"   ‚úÖ OpenAI API Key: {'‚úì Configured' if os.getenv('OPENAI_API_KEY') else '‚ùå Missing'}\")\n",
    "print(f\"   üîß Database: Using SQLite for demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6582f",
   "metadata": {},
   "source": [
    "## Define Data Models and Schema\n",
    "\n",
    "We'll use dataclasses to structure our query results and define the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ebd1e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã HR Database Schema Loaded:\n",
      "   üìä departments: 4 columns\n",
      "   üìä positions: 8 columns\n",
      "   üìä candidates: 7 columns\n",
      "   üìä applications: 6 columns\n",
      "   üìä interviews: 7 columns\n",
      "   üìä offers: 7 columns\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class QueryResult:\n",
    "    \"\"\"Represents the result of a text-to-SQL operation\"\"\"\n",
    "    original_question: str\n",
    "    generated_sql: str\n",
    "    executed_sql: str\n",
    "    data: pd.DataFrame\n",
    "    row_count: int\n",
    "    summary: str\n",
    "    time_filter_applied: Optional[str] = None\n",
    "    assumptions_made: Optional[List[str]] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.assumptions_made is None:\n",
    "            self.assumptions_made = []\n",
    "\n",
    "@dataclass\n",
    "class DatabaseSchema:\n",
    "    \"\"\"Represents our known database schema for validation\"\"\"\n",
    "    tables: Dict[str, List[str]]\n",
    "    relationships: Dict[str, str]\n",
    "    time_columns: Dict[str, str]\n",
    "\n",
    "# Define our HR recruitment database schema\n",
    "HR_SCHEMA = DatabaseSchema(\n",
    "    tables={\n",
    "        'departments': ['department_id', 'department_name', 'hiring_manager', 'budget_usd'],\n",
    "        'positions': ['position_id', 'department_id', 'job_title', 'level', 'salary_min', 'salary_max', 'status', 'posted_date'],\n",
    "        'candidates': ['candidate_id', 'full_name', 'email', 'phone', 'years_experience', 'current_company', 'source'],\n",
    "        'applications': ['application_id', 'candidate_id', 'position_id', 'application_date', 'status', 'resume_score'],\n",
    "        'interviews': ['interview_id', 'application_id', 'interview_date', 'interview_type', 'interviewer_name', 'rating', 'feedback_summary'],\n",
    "        'offers': ['offer_id', 'application_id', 'offer_date', 'salary_offered', 'signing_bonus', 'status', 'response_date']\n",
    "    },\n",
    "    relationships={\n",
    "        'positions.department_id': 'departments.department_id',\n",
    "        'applications.candidate_id': 'candidates.candidate_id',\n",
    "        'applications.position_id': 'positions.position_id',\n",
    "        'interviews.application_id': 'applications.application_id',\n",
    "        'offers.application_id': 'applications.application_id'\n",
    "    },\n",
    "    time_columns={\n",
    "        'positions': 'posted_date',\n",
    "        'applications': 'application_date',\n",
    "        'interviews': 'interview_date',\n",
    "        'offers': 'offer_date'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"üìã HR Database Schema Loaded:\")\n",
    "for table, columns in HR_SCHEMA.tables.items():\n",
    "    print(f\"   üìä {table}: {len(columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8063a74",
   "metadata": {},
   "source": [
    "## Database Connection and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca093ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Connecting to HR recruitment database...\n",
      "‚úÖ Database connection successful!\n",
      "üìã Database Statistics:\n",
      "   üìä departments: 8 records\n",
      "   üìä positions: 39 records\n",
      "   üìä candidates: 200 records\n",
      "   üìä applications: 263 records\n",
      "   üìä interviews: 402 records\n",
      "   üìä offers: 76 records\n",
      "   üí∞ Average salary offered: $146,671\n",
      "   üë• Total hires: 42\n",
      "   üìÖ Data range: Last 180 days of recruitment data\n",
      "ü§ñ Ready to initialize the HR Text-to-SQL Agent!\n"
     ]
    }
   ],
   "source": [
    "def get_schema_description(schema: DatabaseSchema) -> str:\n",
    "    \"\"\"Get a formatted description of database schema for LLM\"\"\"\n",
    "    desc = \"Available Tables and Columns:\\n\"\n",
    "    \n",
    "    for table, columns in schema.tables.items():\n",
    "        desc += f\"\\n{table}:\\n\"\n",
    "        for col in columns:\n",
    "            desc += f\"  - {col}\\n\"\n",
    "    \n",
    "    desc += \"\\nKey Relationships:\\n\"\n",
    "    for rel, target in schema.relationships.items():\n",
    "        desc += f\"  - {rel} ‚Üí {target}\\n\"\n",
    "        \n",
    "    desc += \"\\nTime Columns (for filtering):\\n\"\n",
    "    for table, time_col in schema.time_columns.items():\n",
    "        desc += f\"  - {table}.{time_col}\\n\"\n",
    "            \n",
    "    return desc\n",
    "\n",
    "def check_database_exists():\n",
    "    \"\"\"Check if the HR database exists and show stats\"\"\"\n",
    "    db_path = \"hr_recruitment.db\"\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"‚ùå Database file '{db_path}' not found!\")\n",
    "        print(\"   Run 'python3 setup_hr_database.py' first to create the database.\")\n",
    "        return False\n",
    "    \n",
    "    # Connect and show stats\n",
    "    engine = create_engine(f\"sqlite:///{db_path}\", echo=False)\n",
    "    with engine.connect() as conn:\n",
    "        # Get table counts\n",
    "        tables_info = []\n",
    "        for table in HR_SCHEMA.tables.keys():\n",
    "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {table}\"))\n",
    "            count = result.fetchone()[0]\n",
    "            tables_info.append(f\"   üìä {table}: {count:,} records\")\n",
    "        \n",
    "        # Get key metrics\n",
    "        result = conn.execute(text(\"SELECT AVG(salary_offered) FROM offers\"))\n",
    "        avg_salary = result.fetchone()[0]\n",
    "        \n",
    "        result = conn.execute(text(\"SELECT COUNT(*) FROM applications WHERE status = 'Hired'\"))\n",
    "        hired_count = result.fetchone()[0]\n",
    "        \n",
    "        print(\"‚úÖ Database connection successful!\")\n",
    "        print(\"üìã Database Statistics:\")\n",
    "        for info in tables_info:\n",
    "            print(info)\n",
    "        print(f\"   üí∞ Average salary offered: ${avg_salary:,.0f}\")\n",
    "        print(f\"   üë• Total hires: {hired_count}\")\n",
    "        print(f\"   üìÖ Data range: Last 180 days of recruitment data\")\n",
    "    \n",
    "    return engine\n",
    "\n",
    "# Initialize database connection\n",
    "print(\"üîó Connecting to HR recruitment database...\")\n",
    "engine = check_database_exists()\n",
    "\n",
    "if engine:\n",
    "    print(\"ü§ñ Ready to initialize the HR Text-to-SQL Agent!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please run the database setup script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540beec6",
   "metadata": {},
   "source": [
    "## Build the HR Text-to-SQL Agent\n",
    "\n",
    "The agent orchestrates multiple capabilities:\n",
    "1. **SQL Generation**: Converts natural language to SQL using LLM\n",
    "2. **Safety Validation**: Applies guardrails before execution\n",
    "3. **Query Execution**: Runs safe queries and returns data\n",
    "4. **Summary Generation**: Creates professional explanations\n",
    "5. **Retry Logic**: Handles errors with feedback loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97ae73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ HR Text-to-SQL Agent initialized and ready!\n"
     ]
    }
   ],
   "source": [
    "class HRTextToSQLAgent:\n",
    "    \"\"\"AI agent for converting natural language to safe SQL queries for HR operations\"\"\"\n",
    "    \n",
    "    def __init__(self, engine, schema: DatabaseSchema):\n",
    "        self.engine = engine\n",
    "        self.schema = schema\n",
    "        self.query_history = []\n",
    "        \n",
    "    def process_question(self, question: str, show_sql_answer: bool = False) -> QueryResult:\n",
    "        \"\"\"\n",
    "        Main method to process a natural language question\n",
    "        \n",
    "        Args:\n",
    "            question: Natural language question about HR data\n",
    "            show_sql_answer: Whether to display SQL queries during processing\n",
    "            \n",
    "        Returns:\n",
    "            QueryResult with SQL, data, and summary\n",
    "        \"\"\"\n",
    "        print(f\"üîç Processing: {question}\")\n",
    "        \n",
    "        # Step 1: Generate SQL from natural language with retry logic\n",
    "        generated_sql, generation_attempts = self._generate_sql_with_retry(question, show_sql_answer)\n",
    "        if show_sql_answer:\n",
    "            print(f\"üìù Generated SQL (attempt {generation_attempts}): {generated_sql}\")\n",
    "        \n",
    "        # Step 2: Apply safety checks and modifications\n",
    "        safe_sql, assumptions = self._apply_safety_checks(generated_sql, question)\n",
    "        if show_sql_answer:\n",
    "            print(f\"üõ°Ô∏è Safe SQL: {safe_sql}\")\n",
    "        \n",
    "        # Step 3: Execute the query\n",
    "        data, row_count = self._execute_query(safe_sql)\n",
    "        \n",
    "        # Step 4: Generate summary\n",
    "        summary = self._generate_summary(question, safe_sql, data, assumptions)\n",
    "        \n",
    "        # Create and store result\n",
    "        result = QueryResult(\n",
    "            original_question=question,\n",
    "            generated_sql=generated_sql,\n",
    "            executed_sql=safe_sql,\n",
    "            data=data,\n",
    "            row_count=row_count,\n",
    "            summary=summary,\n",
    "            assumptions_made=assumptions\n",
    "        )\n",
    "        \n",
    "        self.query_history.append(result)\n",
    "        return result\n",
    "    \n",
    "    def _generate_sql_with_retry(self, question: str, show_sql_answer: bool = False, max_attempts: int = 3) -> Tuple[str, int]:\n",
    "        \"\"\"Generate SQL with retry logic and error feedback\"\"\"\n",
    "        last_error = None\n",
    "        \n",
    "        for attempt in range(1, max_attempts + 1):\n",
    "            try:\n",
    "                sql = self._generate_sql(question, previous_error=last_error, attempt=attempt)\n",
    "                validation_error = self._validate_sql_syntax(sql)\n",
    "                \n",
    "                if validation_error is None:\n",
    "                    if attempt > 1 and show_sql_answer:\n",
    "                        print(f\"‚úÖ SQL generation successful on attempt {attempt}\")\n",
    "                    return sql, attempt\n",
    "                else:\n",
    "                    last_error = validation_error\n",
    "                    if show_sql_answer:\n",
    "                        print(f\"‚ùå Attempt {attempt} failed: {validation_error}\")\n",
    "                        if attempt < max_attempts:\n",
    "                            print(f\"üîÑ Retry attempt {attempt + 1} with error feedback...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                last_error = f\"Generation error: {str(e)}\"\n",
    "                if show_sql_answer:\n",
    "                    print(f\"‚ùå Attempt {attempt} failed: {last_error}\")\n",
    "        \n",
    "        if show_sql_answer:\n",
    "            print(f\"‚ö†Ô∏è  All {max_attempts} attempts failed, using last attempt\")\n",
    "        return sql, max_attempts\n",
    "    \n",
    "    def _generate_sql(self, question: str, previous_error: Optional[str] = None, attempt: int = 1) -> str:\n",
    "        \"\"\"Generate SQL query from natural language using LLM\"\"\"\n",
    "        \n",
    "        schema_info = get_schema_description(self.schema)\n",
    "        \n",
    "        base_rules = \"\"\"Important Rules:\n",
    "1. Only use SELECT statements (no INSERT, UPDATE, DELETE, DROP, etc.)\n",
    "2. Only query from the tables listed above\n",
    "3. Always include a LIMIT clause (max 20 rows)\n",
    "4. For time-based queries, include appropriate date filters\n",
    "5. Use proper JOINs to get related data\n",
    "6. Use meaningful column aliases for readability\n",
    "7. Order results logically\n",
    "8. **CRITICAL: Use SQLite functions ONLY - NO MySQL/PostgreSQL syntax**\n",
    "\n",
    "SQLite Date/Time Functions (USE THESE):\n",
    "- Time filters: application_date >= date('now', '-30 days')\n",
    "- Extract month: strftime('%m', application_date) AS month\n",
    "- Extract year: strftime('%Y', application_date) AS year\n",
    "- Month name: strftime('%B', application_date) AS month_name\n",
    "\n",
    "FORBIDDEN Functions (DO NOT USE):\n",
    "- MONTH() ‚ùå Use strftime('%m', date_column) ‚úÖ\n",
    "- YEAR() ‚ùå Use strftime('%Y', date_column) ‚úÖ  \n",
    "- NOW() ‚ùå Use date('now') ‚úÖ\n",
    "- INTERVAL ‚ùå Use date('now', '-X days') ‚úÖ\"\"\"\n",
    "        \n",
    "        error_feedback = \"\"\n",
    "        if previous_error and attempt > 1:\n",
    "            error_feedback = f\"\\nPREVIOUS ATTEMPT FAILED with error: {previous_error}\\nFix the previous error and generate a corrected SQL query.\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"You are a SQL expert helping HR teams analyze recruitment data. Convert this natural language question into a SELECT SQL query.\n",
    "\n",
    "Database Schema:\n",
    "{schema_info}\n",
    "\n",
    "{error_feedback}{base_rules}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Return only the SQL query, no explanations or markdown formatting:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt},\n",
    "                    {\"role\": \"user\", \"content\": question}\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=500\n",
    "            )\n",
    "            \n",
    "            sql = response.choices[0].message.content.strip()\n",
    "            sql = re.sub(r'```sql\\n?', '', sql)\n",
    "            sql = re.sub(r'```\\n?', '', sql)\n",
    "            \n",
    "            return sql\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating SQL: {e}\")\n",
    "            return \"SELECT 'Error generating SQL' as error_message LIMIT 1;\"\n",
    "    \n",
    "    def _validate_sql_syntax(self, sql: str) -> Optional[str]:\n",
    "        \"\"\"Quick validation of SQL syntax\"\"\"\n",
    "        sql_upper = sql.upper().strip()\n",
    "        \n",
    "        # Check for common MySQL/PostgreSQL syntax issues\n",
    "        if 'MONTH(' in sql_upper or 'YEAR(' in sql_upper:\n",
    "            return \"Invalid function: Use strftime() instead of MONTH()/YEAR()\"\n",
    "        \n",
    "        if 'NOW()' in sql_upper and 'INTERVAL' in sql_upper:\n",
    "            return \"Invalid syntax: Use date('now', '-X days') instead of NOW() - INTERVAL\"\n",
    "        \n",
    "        if not sql_upper.startswith('SELECT'):\n",
    "            return \"Query must start with SELECT\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _apply_safety_checks(self, sql: str, question: str) -> Tuple[str, List[str]]:\n",
    "        \"\"\"Apply safety checks and modifications to the generated SQL\"\"\"\n",
    "        \n",
    "        assumptions = []\n",
    "        sql_upper = sql.upper().strip()\n",
    "        \n",
    "        # 1. Ensure it's a SELECT statement\n",
    "        if not sql_upper.startswith('SELECT'):\n",
    "            return \"SELECT 'Error: Only SELECT queries are allowed' as error_message;\", [\"Query rejected - only SELECT allowed\"]\n",
    "        \n",
    "        # 2. Check for forbidden keywords\n",
    "        forbidden = ['INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER', 'EXEC']\n",
    "        for keyword in forbidden:\n",
    "            if keyword in sql_upper:\n",
    "                return f\"SELECT 'Error: {keyword} operations not allowed' as error_message;\", [f\"Query rejected - {keyword} not allowed\"]\n",
    "        \n",
    "        # 3. Ensure LIMIT is present\n",
    "        if 'LIMIT' not in sql_upper:\n",
    "            sql = sql.rstrip(';') + ' LIMIT 20;'\n",
    "            assumptions.append(\"Added LIMIT 20 for performance\")\n",
    "        \n",
    "        return sql, assumptions\n",
    "    \n",
    "    def _execute_query(self, sql: str) -> Tuple[pd.DataFrame, int]:\n",
    "        \"\"\"Execute SQL query and return results as DataFrame\"\"\"\n",
    "        \n",
    "        try:\n",
    "            with self.engine.connect() as conn:\n",
    "                result = conn.execute(text(sql))\n",
    "                df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "                row_count = len(df)\n",
    "                \n",
    "                print(f\"üìä Query executed: {row_count} rows returned\")\n",
    "                return df, row_count\n",
    "                \n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"‚ùå Database error: {e}\")\n",
    "            error_df = pd.DataFrame({'error': [f\"Database error: {str(e)}\"]})\n",
    "            return error_df, 0\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Execution error: {e}\")\n",
    "            error_df = pd.DataFrame({'error': [f\"Execution error: {str(e)}\"]})\n",
    "            return error_df, 0\n",
    "    \n",
    "    def _generate_summary(self, question: str, sql: str, data: pd.DataFrame, assumptions: List[str]) -> str:\n",
    "        \"\"\"Generate natural language summary of query results\"\"\"\n",
    "        \n",
    "        if 'error' in data.columns:\n",
    "            return f\"Query failed: {data['error'].iloc[0]}\"\n",
    "        \n",
    "        row_count = len(data)\n",
    "        summary_stats = self._get_data_summary(data)\n",
    "        \n",
    "        prompt = f\"\"\"You are an HR analyst summarizing query results for a recruitment team.\n",
    "\n",
    "Original Question: {question}\n",
    "SQL Executed: {sql}\n",
    "Rows Returned: {row_count}\n",
    "Data Summary: {summary_stats}\n",
    "Assumptions: {', '.join(assumptions) if assumptions else 'None'}\n",
    "\n",
    "Write a 2-4 sentence professional summary that:\n",
    "1. Describes what was analyzed\n",
    "2. Mentions any assumptions made\n",
    "3. Highlights key insights from the results\n",
    "4. Uses clear language for HR staff\n",
    "\n",
    "Summary:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt},\n",
    "                    {\"role\": \"user\", \"content\": \"Generate the summary.\"}\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "                max_tokens=200\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating summary: {e}\")\n",
    "            assumptions_text = f\" (Assumptions: {', '.join(assumptions)})\" if assumptions else \"\"\n",
    "            return f\"Query returned {row_count} rows{assumptions_text}. Review results for insights.\"\n",
    "    \n",
    "    def _get_data_summary(self, data: pd.DataFrame) -> str:\n",
    "        \"\"\"Get summary statistics for LLM context\"\"\"\n",
    "        \n",
    "        if data.empty:\n",
    "            return \"No data returned\"\n",
    "        \n",
    "        stats = []\n",
    "        \n",
    "        # Numeric columns (salary, counts, etc.)\n",
    "        numeric_cols = [col for col in data.columns if data[col].dtype in ['float64', 'int64']]\n",
    "        for col in numeric_cols[:3]:  # First 3 numeric columns\n",
    "            if 'salary' in col.lower() or 'bonus' in col.lower():\n",
    "                total = data[col].sum()\n",
    "                avg = data[col].mean()\n",
    "                stats.append(f\"{col} total: ${total:,.0f}, average: ${avg:,.0f}\")\n",
    "            else:\n",
    "                total = data[col].sum()\n",
    "                stats.append(f\"{col} total: {total:,}\")\n",
    "        \n",
    "        # Categorical columns\n",
    "        categorical_cols = [col for col in data.columns if data[col].dtype == 'object']\n",
    "        for col in categorical_cols[:2]:\n",
    "            unique_count = data[col].nunique()\n",
    "            stats.append(f\"{col}: {unique_count} unique values\")\n",
    "        \n",
    "        return \"; \".join(stats) if stats else \"Mixed data types\"\n",
    "\n",
    "# Initialize the agent\n",
    "agent = HRTextToSQLAgent(engine, HR_SCHEMA)\n",
    "print(\"ü§ñ HR Text-to-SQL Agent initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e1b7d",
   "metadata": {},
   "source": [
    "## Utility Functions for Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b3582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Display utilities loaded\n"
     ]
    }
   ],
   "source": [
    "def display_result(result: QueryResult, show_sql: bool = True):\n",
    "    \"\"\"Display query result in a formatted, professional way\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìä HR DATABASE QUERY RESULT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüîç Question:\")\n",
    "    print(f\"   {result.original_question}\")\n",
    "    \n",
    "    if show_sql:\n",
    "        print(f\"\\nüìù Executed SQL:\")\n",
    "        print(f\"   {result.executed_sql}\")\n",
    "    \n",
    "    if result.assumptions_made:\n",
    "        print(f\"\\n‚ö†Ô∏è Assumptions Made:\")\n",
    "        for assumption in result.assumptions_made:\n",
    "            print(f\"   ‚Ä¢ {assumption}\")\n",
    "    \n",
    "    print(f\"\\nüìä Results ({result.row_count} rows):\")\n",
    "    if not result.data.empty and 'error' not in result.data.columns:\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.max_colwidth', 30)\n",
    "        print(result.data.to_string(index=False, max_rows=20))\n",
    "    else:\n",
    "        print(\"   No data returned or error occurred\")\n",
    "    \n",
    "    print(f\"\\nüí° Summary:\")\n",
    "    print(f\"   {result.summary}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"‚úÖ Display utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814a6e6",
   "metadata": {},
   "source": [
    "## Demo: Natural Language to SQL for HR Analytics\n",
    "\n",
    "Let's test our agent with typical HR recruitment questions. The database contains 200+ candidates, 39 positions, 263 applications, 402 interviews, and 76 offers over 180 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4c7e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test Case 1: Hiring activity by department\n",
      "üîç Processing: Show me the top 5 departments by number of positions posted in the last 90 days\n",
      "üìù Generated SQL (attempt 1): SELECT d.department_name AS department, COUNT(p.position_id) AS positions_posted\n",
      "FROM departments d\n",
      "JOIN positions p ON d.department_id = p.department_id\n",
      "WHERE p.posted_date >= date('now', '-90 days')\n",
      "GROUP BY d.department_id\n",
      "ORDER BY positions_posted DESC\n",
      "LIMIT 5;\n",
      "üõ°Ô∏è Safe SQL: SELECT d.department_name AS department, COUNT(p.position_id) AS positions_posted\n",
      "FROM departments d\n",
      "JOIN positions p ON d.department_id = p.department_id\n",
      "WHERE p.posted_date >= date('now', '-90 days')\n",
      "GROUP BY d.department_id\n",
      "ORDER BY positions_posted DESC\n",
      "LIMIT 5;\n",
      "üìä Query executed: 5 rows returned\n",
      "================================================================================\n",
      "üìä HR DATABASE QUERY RESULT\n",
      "================================================================================\n",
      "\n",
      "üîç Question:\n",
      "   Show me the top 5 departments by number of positions posted in the last 90 days\n",
      "\n",
      "üìä Results (5 rows):\n",
      "        department  positions_posted\n",
      "         Marketing                 5\n",
      "             Sales                 5\n",
      "Product Management                 5\n",
      "      Data Science                 4\n",
      "       Engineering                 4\n",
      "\n",
      "üí° Summary:\n",
      "   The analysis focused on identifying the top five departments with the highest number of positions posted in the last 90 days. No specific assumptions were made during this analysis. The results revealed a total of 23 positions posted across five unique departments, indicating active recruitment efforts in these areas. This information can help the recruitment team prioritize their efforts and resources effectively.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Top departments by hiring activity\n",
    "print(\"üß™ Test Case 1: Hiring activity by department\")\n",
    "result1 = agent.process_question(\"Show me the top 5 departments by number of positions posted in the last 90 days\", show_sql_answer=True)\n",
    "display_result(result1, show_sql=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9989e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Case 2: Candidate pipeline by status\n",
      "üîç Processing: Count of applications by status, show me the funnel\n",
      "üìä Query executed: 7 rows returned\n",
      "================================================================================\n",
      "üìä HR DATABASE QUERY RESULT\n",
      "================================================================================\n",
      "\n",
      "üîç Question:\n",
      "   Count of applications by status, show me the funnel\n",
      "\n",
      "üìä Results (7 rows):\n",
      "      status  application_count\n",
      "   Interview                 46\n",
      "       Hired                 42\n",
      "   Withdrawn                 38\n",
      "     Applied                 37\n",
      "Phone Screen                 34\n",
      "       Offer                 34\n",
      "    Rejected                 32\n",
      "\n",
      "üí° Summary:\n",
      "   The analysis focused on the count of job applications categorized by their current status, providing a clear view of the recruitment funnel. A total of 263 applications were analyzed, revealing 7 unique status values. No assumptions were made during this analysis. The results indicate a diverse range of application statuses, which can help the recruitment team identify areas for improvement in the hiring process.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2: Candidate pipeline analysis\n",
    "print(\"\\nüß™ Test Case 2: Candidate pipeline by status\")\n",
    "result2 = agent.process_question(\"Count of applications by status, show me the funnel\")\n",
    "display_result(result2, show_sql=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c4aa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Case 3: Salary offers by department\n",
      "üîç Processing: Average salary offered by department, include number of offers made\n",
      "üìä Query executed: 5 rows returned\n",
      "================================================================================\n",
      "üìä HR DATABASE QUERY RESULT\n",
      "================================================================================\n",
      "\n",
      "üîç Question:\n",
      "   Average salary offered by department, include number of offers made\n",
      "\n",
      "üìù Executed SQL:\n",
      "   SELECT d.department_name AS department, \n",
      "       AVG(o.salary_offered) AS average_salary_offered, \n",
      "       COUNT(o.offer_id) AS number_of_offers\n",
      "FROM offers o\n",
      "JOIN applications a ON o.application_id = a.application_id\n",
      "JOIN positions p ON a.position_id = p.position_id\n",
      "JOIN departments d ON p.department_id = d.department_id\n",
      "GROUP BY d.department_name\n",
      "ORDER BY d.department_name\n",
      "LIMIT 20;\n",
      "\n",
      "üìä Results (5 rows):\n",
      "        department  average_salary_offered  number_of_offers\n",
      "      Data Science           126683.230769                13\n",
      "       Engineering           140305.000000                13\n",
      "         Marketing           130349.136364                22\n",
      "Product Management           192852.076923                13\n",
      "             Sales           153425.933333                15\n",
      "\n",
      "üí° Summary:\n",
      "   The analysis focused on the average salary offered by department, along with the total number of offers made. No specific assumptions were made during this analysis. The results revealed a total average salary offered of $743,615 across five unique departments, with an average salary of $148,723 and a total of 76 offers made. This information can help the recruitment team understand salary trends within different departments and make informed decisions moving forward.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Case 3: Salary analysis\n",
    "print(\"\\nüß™ Test Case 3: Salary offers by department\")\n",
    "result3 = agent.process_question(\"Average salary offered by department, include number of offers made\")\n",
    "display_result(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee29d2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Case 4: Top rated candidates\n",
      "üîç Processing: Show candidates with average interview rating above 4, include their name, current company, and average rating\n",
      "üìä Query executed: 7 rows returned\n",
      "================================================================================\n",
      "üìä HR DATABASE QUERY RESULT\n",
      "================================================================================\n",
      "\n",
      "üîç Question:\n",
      "   Show candidates with average interview rating above 4, include their name, current company, and average rating\n",
      "\n",
      "üìù Executed SQL:\n",
      "   SELECT c.full_name AS candidate_name, c.current_company AS company, AVG(i.rating) AS average_rating\n",
      "FROM candidates c\n",
      "JOIN applications a ON c.candidate_id = a.candidate_id\n",
      "JOIN interviews i ON a.application_id = i.application_id\n",
      "GROUP BY c.candidate_id\n",
      "HAVING AVG(i.rating) > 4\n",
      "ORDER BY average_rating DESC\n",
      "LIMIT 20;\n",
      "\n",
      "üìä Results (7 rows):\n",
      " candidate_name    company  average_rating\n",
      "  Skylar Thomas     GitHub        5.000000\n",
      "    Sage Miller       None        5.000000\n",
      "   Reese Wilson Salesforce        5.000000\n",
      "    Ryan Wilson       None        4.666667\n",
      "      Avery Lee     PayPal        4.333333\n",
      "Skylar Gonzalez  Atlassian        4.333333\n",
      "  Reese Johnson     GitHub        4.250000\n",
      "\n",
      "üí° Summary:\n",
      "   The analysis focused on identifying candidates who received an average interview rating above 4, highlighting their names, current companies, and average ratings. No specific assumptions were made during this analysis. The results revealed a total of 7 unique candidates, representing 4 different companies, with an overall average rating of approximately 32.58 across all candidates. This indicates a strong performance in interviews among the selected candidates, suggesting they are highly regarded by interviewers.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Case 4: Interview performance\n",
    "print(\"\\nüß™ Test Case 4: Top rated candidates\")\n",
    "result4 = agent.process_question(\"Show candidates with average interview rating above 4, include their name, current company, and average rating\")\n",
    "display_result(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9025ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Case 5: Recruiting source effectiveness\n",
      "üîç Processing: Which recruiting sources brought in candidates that got hired? Show source, number of hires, and conversion rate\n",
      "üìù Generated SQL (attempt 1): SELECT \n",
      "    c.source AS recruiting_source, \n",
      "    COUNT(DISTINCT a.candidate_id) AS number_of_hires, \n",
      "    (COUNT(DISTINCT a.candidate_id) * 1.0 / COUNT(DISTINCT a.application_id)) * 100 AS conversion_rate\n",
      "FROM \n",
      "    candidates c\n",
      "JOIN \n",
      "    applications a ON c.candidate_id = a.candidate_id\n",
      "JOIN \n",
      "    offers o ON a.application_id = o.application_id\n",
      "WHERE \n",
      "    o.status = 'hired'\n",
      "GROUP BY \n",
      "    c.source\n",
      "ORDER BY \n",
      "    number_of_hires DESC\n",
      "LIMIT 20;\n",
      "üõ°Ô∏è Safe SQL: SELECT \n",
      "    c.source AS recruiting_source, \n",
      "    COUNT(DISTINCT a.candidate_id) AS number_of_hires, \n",
      "    (COUNT(DISTINCT a.candidate_id) * 1.0 / COUNT(DISTINCT a.application_id)) * 100 AS conversion_rate\n",
      "FROM \n",
      "    candidates c\n",
      "JOIN \n",
      "    applications a ON c.candidate_id = a.candidate_id\n",
      "JOIN \n",
      "    offers o ON a.application_id = o.application_id\n",
      "WHERE \n",
      "    o.status = 'hired'\n",
      "GROUP BY \n",
      "    c.source\n",
      "ORDER BY \n",
      "    number_of_hires DESC\n",
      "LIMIT 20;\n",
      "üìä Query executed: 0 rows returned\n",
      "================================================================================\n",
      "üìä HR DATABASE QUERY RESULT\n",
      "================================================================================\n",
      "\n",
      "üîç Question:\n",
      "   Which recruiting sources brought in candidates that got hired? Show source, number of hires, and conversion rate\n",
      "\n",
      "üìä Results (0 rows):\n",
      "   No data returned or error occurred\n",
      "\n",
      "üí° Summary:\n",
      "   The analysis focused on identifying which recruiting sources contributed to the hiring of candidates, including the number of hires and their respective conversion rates. No data was returned from the query, indicating that there were no candidates hired from any recruiting sources during the specified timeframe. This suggests a potential gap in recruitment effectiveness or a lack of recent hiring activity that should be further investigated by the recruitment team.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Case 5: Recruiting source effectiveness\n",
    "print(\"\\nüß™ Test Case 5: Recruiting source effectiveness\")\n",
    "result5 = agent.process_question(\"Which recruiting sources brought in candidates that got hired? Show source, number of hires, and conversion rate\", show_sql_answer=True)\n",
    "display_result(result5, show_sql=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbee84",
   "metadata": {},
   "source": [
    "## Safety Validation Tests\n",
    "\n",
    "Let's verify our safety guardrails prevent dangerous operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25a0d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ°Ô∏è Safety Test 1: Attempt to DELETE data\n",
      "üîç Processing: Delete all rejected applications\n",
      "üìä Query executed: 0 rows returned\n",
      "================================================================================\n",
      "üìä HR DATABASE QUERY RESULT\n",
      "================================================================================\n",
      "\n",
      "üîç Question:\n",
      "   Delete all rejected applications\n",
      "\n",
      "üìù Executed SQL:\n",
      "   SELECT * FROM applications WHERE status = 'rejected' LIMIT 20;\n",
      "\n",
      "üìä Results (0 rows):\n",
      "   No data returned or error occurred\n",
      "\n",
      "üí° Summary:\n",
      "   The analysis focused on identifying rejected applications within the recruitment database. No assumptions were made during this query. The results indicated that there were no rejected applications present, as the SQL query returned zero rows. This suggests that the current application pool does not contain any candidates who have been marked as rejected.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Safety Test 1: Attempt forbidden operations\n",
    "print(\"üõ°Ô∏è Safety Test 1: Attempt to DELETE data\")\n",
    "safety_result1 = agent.process_question(\"Delete all rejected applications\")\n",
    "display_result(safety_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "babded80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üõ°Ô∏è Safety Test 2: Missing LIMIT - should add default\n",
      "üîç Processing: Show all candidates who applied to Engineering positions\n",
      "üìä Query executed: 20 rows returned\n",
      "================================================================================\n",
      "üìä HR DATABASE QUERY RESULT\n",
      "================================================================================\n",
      "\n",
      "üîç Question:\n",
      "   Show all candidates who applied to Engineering positions\n",
      "\n",
      "üìù Executed SQL:\n",
      "   SELECT c.candidate_id AS CandidateID, c.full_name AS FullName, c.email AS Email, c.phone AS Phone, c.years_experience AS YearsExperience, c.current_company AS CurrentCompany, c.source AS Source\n",
      "FROM candidates c\n",
      "JOIN applications a ON c.candidate_id = a.candidate_id\n",
      "JOIN positions p ON a.position_id = p.position_id\n",
      "JOIN departments d ON p.department_id = d.department_id\n",
      "WHERE d.department_name = 'Engineering'\n",
      "LIMIT 20;\n",
      "\n",
      "üìä Results (20 rows):\n",
      " CandidateID         FullName                        Email           Phone  YearsExperience CurrentCompany          Source\n",
      "         129      River Smith      river.smith@example.com +1-555-483-5752               14           Meta       Recruiter\n",
      "          13     Sam Thompson     sam.thompson@example.com +1-555-998-1700               12           None       Recruiter\n",
      "         197    Hayden Thomas    hayden.thomas@example.com +1-555-644-9393                0          Adobe       Recruiter\n",
      "          75 Kendall Gonzalez kendall.gonzalez@example.com +1-555-106-7233               14          Apple          Indeed\n",
      "         193      Avery Smith      avery.smith@example.com +1-555-515-3428                0           Zoom        Referral\n",
      "         118   Peyton Johnson   peyton.johnson@example.com +1-555-594-3542                8         Google       Glassdoor\n",
      "          25    Blake Johnson    blake.johnson@example.com +1-555-152-2887                5        Twitter       Recruiter\n",
      "         168        Avery Lee        avery.lee@example.com +1-555-481-6180                3         PayPal       Recruiter\n",
      "          82   Casey Anderson   casey.anderson@example.com +1-555-245-1022                5          Asana Company Website\n",
      "          70       Alex Smith       alex.smith@example.com +1-555-734-5776                5          Asana          Indeed\n",
      "          66       Peyton Lee       peyton.lee@example.com +1-555-438-2492                5           None       AngelList\n",
      "          55     Sage Jackson     sage.jackson@example.com +1-555-568-5283                0           None       Recruiter\n",
      "          12    Kendall Lopez    kendall.lopez@example.com +1-555-477-5007                5           None       AngelList\n",
      "         200       Sage Moore       sage.moore@example.com +1-555-654-6226                6     Salesforce          Indeed\n",
      "          80      Quinn Davis      quinn.davis@example.com +1-555-298-2364               11           Zoom       Recruiter\n",
      "          60  Skylar Gonzalez  skylar.gonzalez@example.com +1-555-940-4000                6      Atlassian        LinkedIn\n",
      "          77   Skylar Jackson   skylar.jackson@example.com +1-555-649-4710                7            IBM        LinkedIn\n",
      "         104      Avery Jones      avery.jones@example.com +1-555-535-3030                6     Salesforce        LinkedIn\n",
      "          84  Reese Hernandez  reese.hernandez@example.com +1-555-109-4164               11         PayPal       Recruiter\n",
      "         150    Dakota Martin    dakota.martin@example.com +1-555-694-9416               11           Zoom Company Website\n",
      "\n",
      "üí° Summary:\n",
      "   The analysis focused on candidates who applied for Engineering positions, resulting in a dataset of 20 records. There were no assumptions made during this analysis. Key insights reveal that a total of 1,958 candidates applied for these roles, with a combined years of experience amounting to 134 years. Additionally, the results included 20 unique full names and email addresses, indicating a diverse pool of applicants.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Safety Test 2: Missing LIMIT clause\n",
    "print(\"\\nüõ°Ô∏è Safety Test 2: Missing LIMIT - should add default\")\n",
    "safety_result2 = agent.process_question(\"Show all candidates who applied to Engineering positions\")\n",
    "display_result(safety_result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823486a3",
   "metadata": {},
   "source": [
    "## Key Learning Points\n",
    "\n",
    "### ‚úÖ **Core Features Demonstrated**\n",
    "\n",
    "1. **Natural Language Processing**: Converts plain English questions to SQL using LLMs\n",
    "2. **Safety Guardrails**: Enforces read-only operations, table whitelisting, and row limits  \n",
    "3. **Schema-Aware Processing**: Understands table relationships and data types\n",
    "4. **Professional Summaries**: Generates clear explanations suitable for HR teams\n",
    "5. **Database Integration**: SQLAlchemy support for multiple database types\n",
    "\n",
    "### üõ°Ô∏è **Security & Safety Measures**\n",
    "\n",
    "- **Query Validation**: Blocks DML operations (INSERT, UPDATE, DELETE, DROP)\n",
    "- **Table Whitelisting**: Only allows queries against approved schema tables\n",
    "- **Automatic Limits**: Adds LIMIT 20 to prevent large result sets\n",
    "- **Error Handling**: Graceful failure with informative error messages\n",
    "- **Retry Logic**: Attempts to fix errors with LLM feedback\n",
    "\n",
    "### üèóÔ∏è **Architecture Highlights**\n",
    "\n",
    "- **Modular Design**: Separate classes for schema, results, and agent logic\n",
    "- **Schema-Aware**: Understands table relationships and data types\n",
    "- **Query History**: Tracks all processed queries for auditing\n",
    "- **Assumption Tracking**: Records when defaults are applied\n",
    "\n",
    "### üí° **Applications to Other Domains**\n",
    "\n",
    "This pattern extends to:\n",
    "- **Finance Operations** (expense tracking, budget analysis)\n",
    "- **Sales Analytics** (pipeline metrics, revenue forecasting)\n",
    "- **Customer Support** (ticket analysis, response times)\n",
    "- **Inventory Management** (stock levels, reorder points)\n",
    "- **Healthcare Analytics** (patient data, appointment scheduling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
